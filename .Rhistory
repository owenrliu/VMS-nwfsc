scale_fill_npg(name="Has 5km Grid")+
xlim(bbox_eureka[1],bbox_eureka[3])+
ylim(bbox_eureka[2],bbox_eureka[4])
eureka_points
# Monterey
monterey <- vms_sf %>%
filter(lat<37,lat>36.3,lon< -121.4,lon>-122.5)
bbox_monterey <- st_bbox(monterey)
monterey_points <- ggplot()+
geom_sf(data=coaststates)+
geom_sf(data=monterey,aes(col=has_grid,fill=has_grid),size=0.5,alpha=0.5)+
scale_color_npg(name="Has 5km Grid")+
scale_fill_npg(name="Has 5km Grid")+
xlim(bbox_monterey[1],bbox_monterey[3])+
ylim(bbox_monterey[2],bbox_monterey[4])
# Eureka
eureka <- vms_sf %>%
filter(lat<41.3,lat>40.5,lon< -123.5,lon>-124.5)
bbox_eureka <- st_bbox(eureka)
eureka_points <- ggplot()+
geom_sf(data=coaststates)+
geom_sf(data=eureka,aes(col=has_grid,fill=has_grid),size=0.5,alpha=0.5)+
scale_color_npg(name="Has 5km Grid")+
scale_fill_npg(name="Has 5km Grid")+
xlim(bbox_eureka[1],bbox_eureka[3])+
ylim(bbox_eureka[2],bbox_eureka[4])
monterey_points
eureka_points
monterey_points <- ggplot()+
geom_sf(data=coaststates)+
geom_sf(data=monterey,aes(col=has_grid,fill=has_grid),size=0.5,alpha=0.5)+
scale_color_npg(name="Has 5km Grid\nassigned")+
scale_fill_npg(name="Has 5km Grid\nassigned")+
xlim(bbox_monterey[1],bbox_monterey[3])+
ylim(bbox_monterey[2],bbox_monterey[4])+
labs(title="Monterey VMS Points")
eureka_points <- ggplot()+
geom_sf(data=coaststates)+
geom_sf(data=eureka,aes(col=has_grid,fill=has_grid),size=0.5,alpha=0.5)+
scale_color_npg(name="Has 5km Grid\nassigned")+
scale_fill_npg(name="Has 5km Grid\nassigned")+
xlim(bbox_eureka[1],bbox_eureka[3])+
ylim(bbox_eureka[2],bbox_eureka[4])+
labs(title="Eureka VMS Points")
monterey_points
eureka_points
median(vms_sf$depth_m[!vms_sf$has_grid])
mean(vms_sf$depth_m[!vms_sf$has_grid])
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(extrafont)
library(ggsci)
library(lubridate)
library(sf)
library(geosphere)
library(magrittr)
library(rnaturalearth)
library(marmap)
# ggplot theme
plot_theme <-   theme_minimal()+
theme(text=element_text(family="Gill Sans MT",size=12,color="black"),
legend.text = element_text(size=14),
axis.title=element_text(family="sans",size=14,color="black"),
axis.text=element_text(family="sans",size=8,color="black"),
panel.grid.major = element_line(color="gray50",linetype=3))
theme_set(plot_theme)
# File path where data are held
fp <- "C:/Users/Owen.Liu/Documents/NWFSC Research/Dungeness Fleet Dynamics/VMS DATA CONFIDENTIAL/Processed Data/VMS/"
fp_tix <- "C:/Users/Owen.Liu/Documents/NWFSC Research/Dungeness Fleet Dynamics/VMS DATA CONFIDENTIAL/Processed Data/Fish tickets/"
# Load Rdata files
# Interpolated, regularized VMS data, all years (spatial version)
vms_sf<-readRDS(file=paste0(fp,"VMS_int_reg_w_grid.rds"))
# non-spatial version of full VMS data
vms <- vms_sf
st_geometry(vms) <- NULL
# fish ticket data
load(file=paste0(fp_tix,"FishTix_all_2009_2018.RData"))
# a coastline, for plotting
# coastline for plotting
coaststates <- ne_states(country='United States of America',returnclass = 'sf') %>%
filter(name %in% c('California','Oregon','Washington'))
coastline <- ne_coastline(scale='medium',returnclass = 'sf') %>%
st_crop(st_bbox(coaststates))
tix_vms_2017 <- fishtix_matched_all %>% filter(year==2018)
tix_vms_2018 <- fishtix_matched_all %>% filter(year==2018)
tix_vms_2017 <- fishtix_matched_all %>% filter(year==2017)
tix_all_2017 <- fishtix_basic_all %>% filter(year==2017)
tix_all_2018 <- fishtix_basic_all %>% filter(year==2017)
tix_all_2018 <- fishtix_basic_all %>% filter(year==2018)
vms_2017 <- vms %>% filter(year==2017)
names(vms)
vms <- vms %>% mutate(year=year(westcoastdate))
head(vms$year)
vms_2017 <- vms %>% filter(year==2017)
vms_2018 <- vms %>% filter(year==2018)
# do vms and fishtix line up
Rec_IDs2017 <- unique(tix_vms_2017$Rec_ID)
# do vms and fishtix line up
tix_vmsonly_Rec_IDs2017 <- unique(tix_vms_2017$Rec_ID)
tix_vmsonly_Rec_IDs2018 <- unique(tix_vms_2018$Rec_ID)
tix_all_Rec_IDs2017 <- unique(tix_all_2017$Rec_ID)
tix_all_Rec_IDs2018 <- unique(tix_all_2018$Rec_ID)
vms_Rec_IDs2017 <- unique(vms_2017$Rec_ID)
vms_Rec_IDs2018 <- unique(vms_2018$Rec_ID)
# look for overlaps
common_RecIDs_2017 <- intersect(tix_vmsonly_Rec_IDs2017,vms_Rec_IDs2017)
common_RecIDs_2018 <- intersect(tix_vmsonly_Rec_IDs2018,vms_Rec_IDs2018)
# look for overlaps
common_RecIDs_alltix_2017 <- intersect(tix_all_Rec_IDs2017,vms_Rec_IDs2017)
common_RecIDs_alltix_2018 <- intersect(tix_all_Rec_IDs2018,vms_Rec_IDs2018)
common_RecIDs_vmstix_2017 <- intersect(tix_vmsonly_Rec_IDs2017,vms_Rec_IDs2017)
common_RecIDs_vmstix_2018 <- intersect(tix_vmsonly_Rec_IDs2018,vms_Rec_IDs2018)
# percentages
length(common_RecIDs_alltix_2017)/length(tix_all_Rec_IDs2017)
paste(length(common_RecIDs_alltix_2018)/length(tix_all_Rec_IDs2018)*100,"percent of all tickets in 2017 match to VMS records")
# percentages
paste(length(common_RecIDs_alltix_2017)/length(tix_all_Rec_IDs2017)*100,"percent of all tickets in 2017 match to VMS records")
paste(length(common_RecIDs_alltix_2018)/length(tix_all_Rec_IDs2018)*100,"percent of all tickets in 2017 match to VMS records")
# percentages
paste(length(common_RecIDs_alltix_2017)/length(tix_all_Rec_IDs2017)*100 %>% signif(2),"percent of all tickets in 2017 match to VMS records")
# percentages
paste(length(common_RecIDs_alltix_2017)/length(tix_all_Rec_IDs2017)*100 %>% signif(0),"percent of all tickets in 2017 match to VMS records")
# percentages
paste(length(common_RecIDs_alltix_2017)/length(tix_all_Rec_IDs2017)*100 %>% round(),"percent of all tickets in 2017 match to VMS records")
# percentages
paste(round(length(common_RecIDs_alltix_2017)/length(tix_all_Rec_IDs2017)*100),"percent of all tickets in 2017 match to VMS records")
paste(round(length(common_RecIDs_alltix_2018)/length(tix_all_Rec_IDs2018)*100),"percent of all tickets in 2017 match to VMS records")
sum(
unique(vms_2017$Rec_ID) %in% unique(tix_all_2017$Rec_ID)
)
sum(
unique(vms_2018$Rec_ID) %in% unique(tix_all_2018$Rec_ID)
)
sum(
unique(vms_2018$Rec_ID) %in% unique(tix_vms_2018$Rec_ID)
)
glimpse(tix_vms_2018)
length(tix_all_2018)
nrow(tix_all_2018)
nrow(tix_vms_2018)
nrow(tix_matched_2018)
tix_vlength_2018 <- fishtix_vlength_all %>% filter(year==2018)
glimpse(fishtix_vlength_all)
tix_vlength_2018 <- fishtix_vlength_all %>% filter(year==2018)
tix_vlength_Rec_IDs2018 <- unique(tix_vlength_2018$Rec_ID)
common_RecIDs_alltix_2018 <- intersect(tix_vlength_Rec_IDs2018,vms_Rec_IDs2018)
names(fishtix_vlength_all)
head(fishtix_vlength_all)
glimpse(fishtix_vlength_all)
glimpse(fishtix_basic_all)
tix_vlength_Rec_IDs2018 <- unique(tix_vlength_2018$Rec_ID)
head(tix_vlength_Rec_IDs2018)
tix_all_Rec_IDs2018 <- unique(tix_all_2018$Rec_ID)
head(tix_all_Rec_IDs2018)
glimpse(fishtix_matched_all)
paste(round(length(common_RecIDs_alltix_2018)/length(tix_all_Rec_IDs2018)*100),"percent of all tickets in 2018 match to VMS records")
tix_all_Rec_IDs2018 <- unique(tix_all_2018$Rec_ID)
tix_vlength_Rec_IDs2018 <- unique(tix_vlength_2018$Rec_ID)
common_RecIDs_2018_vlength_matched <- intersect(tix_vlength_Rec_IDs2018,tix_all_Rec_IDs2018)
common_RecIDs_vms_matched_2018 <- intersect(tix_vmsonly_Rec_IDs2018,vms_Rec_IDs2018)
length(common_RecIDs_vms_matched_2018)
length(unique(vms_2018$Rec_ID))
warnings()
library(installr)
install.packages('installr')
library(installr)
install.rstudio()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(extrafont)
library(ggsci)
library(lubridate)
library(sf)
library(geosphere)
library(magrittr)
library(rnaturalearth)
library(marmap)
# ggplot theme
plot_theme <-   theme_minimal()+
theme(text=element_text(family="Gill Sans MT",size=12,color="black"),
legend.text = element_text(size=14),
axis.title=element_text(family="sans",size=14,color="black"),
axis.text=element_text(family="sans",size=8,color="black"),
panel.grid.major = element_line(color="gray50",linetype=3))
theme_set(plot_theme)
# File path where data are held
fp <- "C:/Users/Owen.Liu/Documents/NWFSC Research/Dungeness Fleet Dynamics/VMS DATA CONFIDENTIAL/Processed Data/VMS/"
fp_tix <- "C:/Users/Owen.Liu/Documents/NWFSC Research/Dungeness Fleet Dynamics/VMS DATA CONFIDENTIAL/Processed Data/Fish tickets/"
# Load Rdata files
# Interpolated, regularized VMS data, all years (spatial version)
vms_sf<-readRDS(file=paste0(fp,"VMS_int_reg_w_grid.rds"))
# non-spatial version of full VMS data
vms <- vms_sf
st_geometry(vms) <- NULL
# fish ticket data
load(file=paste0(fp_tix,"FishTix_all_2009_2018.RData"))
# a coastline, for plotting
# coastline for plotting
coaststates <- ne_states(country='United States of America',returnclass = 'sf') %>%
filter(name %in% c('California','Oregon','Washington'))
coastline <- ne_coastline(scale='medium',returnclass = 'sf') %>%
st_crop(st_bbox(coaststates))
trip1 <- vms_sf %>%
filter(TARGET_max=="DCRB",year(westcoastdate)==2010,month(westcoastdate)==12) %>%
group_by(Rec_ID) %>%
nest() %>%
ungroup() %>%
slice(100) %>%
unnest(cols = c(data)) %>%
st_as_sf(crs=st_crs(vms_sf))
# create individual line segments
# NOTE: This creates look-one-point-ahead line segments
create_linesegs <- function(sf_df){
linesegs <- sf_df %>%
mutate(pt=row_number()) %>%
# create start and end points for each segment by duplicating rows (so that, e.g., the first segment will connect point 1 to 2, the second segment will connect point 2 to 3, etc.)
slice(1,rep(2:(n()-1),each=2),n()) %>%
# line segment identifier, such that the segment for each VMS point is composed of its own point and the next point
mutate(seg=lag(pt,1)) %>% replace_na(list(seg=1)) %>%
# build the lines
group_by(seg) %>%
summarise() %>%
filter(st_geometry_type(.) == "MULTIPOINT") %>%
st_cast("LINESTRING") %>%
ungroup()
return(linesegs)
}
# plot
trip1_lines <- trip1 %>%
create_linesegs()
bbox <- st_bbox(trip1_lines)
ggplot()+
geom_sf(data=trip1_lines,color="black")+
geom_sf(data=coaststates,color='gray50')+
theme(axis.text.x = element_text(angle=45))+
coord_sf(xlim=c(bbox[1],bbox[3]),ylim=c(bbox[2],bbox[4]))+
labs(x="Longitude",y="Latitude",title="A DCRB Trip\nDec 02, 2010")
trip1_trunc <- trip1_lines %>% slice(2:(n()-1))
ggplot()+
geom_sf(data=trip1_trunc,color="black")+
geom_sf(data=coaststates,color='gray50')+
theme(axis.text.x = element_text(angle=45))+
coord_sf(xlim=c(bbox[1],bbox[3]),ylim=c(bbox[2],bbox[4]))+
labs(x="Longitude",y="Latitude",title="A DCRB Trip\nDec 02, 2010\nFirst and Last Segments Removed")
# summarize the trip, adding up total distance traveled
trip1_tot_dist <- sum(st_length(trip1_trunc)) %>% units::set_units(mi) %>% as.numeric()
# calculate the convex hull
trip1_hull <- trip1_trunc %>% ungroup() %>% st_combine() %>% st_convex_hull()
# place random traps
num_traps <- round(trip1_tot_dist*15)
trip1_traps_opt1 <- st_sample(trip1_hull,num_traps)
ggplot()+
geom_sf(data=trip1_hull,fill='darkblue',alpha=0.5)+
geom_sf(data=trip1_traps_opt1,col='black',size=0.5)+
geom_sf(data=coaststates,color='gray50')+
theme(axis.text.x = element_text(angle=45))+
coord_sf(xlim=c(bbox[1],bbox[3]),ylim=c(bbox[2],bbox[4]))+
labs(x="Longitude",y="Latitude",title="A DCRB Trip\nDec 02, 2010\nRandom Trap Placement")
# create segments
trip1_segmentize <- trip1_trunc %>%
ungroup() %>%
summarise(do_union=TRUE) %>%
st_segmentize(units::set_units(1/15,miles))
trip1_traps_opt2 <- trip1_segmentize %>% st_cast("POINT")
ggplot()+
geom_sf(data=trip1_traps_opt2,col='blue',size=0.3)+
labs(x="Longitude",y="Latitude",title="A DCRB Trip\nDec 02, 2010\nLinear Trap Placement")
cols <- c("Random"="black","Linear"="blue","Convex Hull"="darkblue")
shapes <- c("Random"=16,"Linear"=16)
bbox=st_bbox(trip1_trunc)
ggplot()+
geom_sf(data=trip1_hull,aes(fill="Convex Hull"),col=NA,alpha=0.5)+
geom_sf(data=trip1_traps_opt1,aes(colour="Random"),size=0.5,shape=16)+
geom_sf(data=coaststates,color='gray50')+
geom_sf(data=trip1_traps_opt2,aes(colour="Linear"),size=0.3,shape=16)+
scale_color_manual(name="Trap Placement Type",values=cols,
guide=guide_legend(override.aes = list(linetype=c('blank','blank'))))+
scale_fill_manual(name="",values=cols)+
theme(axis.text.x = element_text(angle=45))+
coord_sf(xlim=c(bbox[1],bbox[3]),ylim=c(bbox[2],bbox[4]))+
labs(x="Longitude",y="Latitude",title="Random versus Linear Trap Placement")
# what should the buffer size be? (in meters)
buffer_size <- 1000
# buffer lines
trip1_buffer <- trip1_segmentize %>%
st_transform(st_crs(vms_sf)) %>%
st_buffer(buffer_size) %>%
st_union()
# assign points
trip1_traps_opt3 <- trip1_buffer %>% st_sample(num_traps)
ggplot()+
geom_sf(data=trip1_buffer,col='blue',size=0.3)+
geom_sf(data=trip1_traps_opt3,col='black',size=0.3)+
labs(x="Longitude",y="Latitude",title="A DCRB Trip with 1km buffer")
# create segments and jitter
trip1_traps_opt4 <- trip1_trunc %>%
st_segmentize(units::set_units(1/15,miles)) %>%
st_cast("POINT") %>%
st_jitter(amount=1000)
ggplot()+
geom_sf(data=trip1_traps_opt4,col='blue',size=0.3)+
labs(x="Longitude",y="Latitude",title="A DCRB Trip\nDec 02, 2010\nLinear Trap Placement with Jitter")
# import bathymetry layer (GEBCO 15 arc-second resolution)
# bounding box for the layer (have to translate to lat/lon for bathymetry layer)
bathy <- readGEBCO.bathy(file="C:/Users/Owen.Liu/Documents/NWFSC Research/Dungeness Fleet Dynamics/GEBCO Grid/GEBCO_2019_-132.3021_50.6549_-116.6354_31.2799.nc")
# Function to apply the steps above
# the function takes a set of trip coordinates, a jitter amount in meters, and a number of traps/mile as input and returns a list of trap locations as output
assign_traps <- function(trip,ntraps_per_mi=15,jitter_amount=1000) {
#convert to latlon for depth comparison
linesegs <- trip %>%
# make sure points are in time order
arrange(westcoastdate) %>%
# make lines
create_linesegs() %>%
# remove first and last segments
slice(2:(n()-1))
st_geometry(trip) <- NULL
out <- trip %>%
# identifier for joining segments
mutate(seg=row_number()) %>%
# join line segments
right_join(linesegs,by='seg') %>%
# remove lines where estimated speed is too high
# filter(avg_speed_recalc<4.4) %>%
# segment lines into number of traps
st_as_sf() %>%
st_segmentize(units::set_units(1/ntraps_per_mi,miles)) %>%
st_cast("POINT") %>%
# jitter the traps by a specified number of meters (i.e. draw a random displacement between -jitter and +jitter from a uniform distribution)
st_jitter(amount=jitter_amount) %>%
# filter by depth
st_transform(4326) %>% st_coordinates() %>%
get.depth(bathy,.,locator=FALSE) %>%
mutate(trap_number=row_number()) %>%
filter(depth>-101,depth<0) %>%
# sample 500 or all the traps, whichever is smaller
sample_n(min(500,nrow(.))) %>%
st_as_sf(coords=c('lon','lat'))
print(paste("Trip number",unique(trip$tripnum),"done."))
return(out)
}
# Check with 100 example trips
p <- proc.time()
trip_test <- vms_sf %>%
filter(TARGET_max=="DCRB",year(westcoastdate)==2010,month(westcoastdate)==12) %>%
mutate(tripnum=group_indices(.,Rec_ID)) %>%
filter(tripnum<101) %>%
group_by(Rec_ID) %>%
nest()
proc.time()-p
p <- proc.time()
test2 <- trip_test %>% mutate(traps=purrr::map(data,assign_traps))
proc.time()-p
testplot <- test2$traps[[61]]
st_crs(testplot) <- 4326
ggplot()+
geom_sf(data=coaststates)+
geom_sf(data=testplot,col='black',size=0.3)+
coord_sf(xlim=c(st_bbox(testplot)[1],st_bbox(testplot)[3]),ylim=c(st_bbox(testplot)[2],st_bbox(testplot)[4]))+
labs(x="Longitude",y="Latitude",title="Test of All-in-One Function")
# Load if not already loaded
simulated_traps <- readRDS(file=paste0(fp,"sim_traps_speed_depth_filters.rds")) %>% ungroup()
# traps locations only (discard VMS data for now), attached to fish ticket data
traplocs <- simulated_traps %>% select(Rec_ID,traps) %>%
left_join(fishtix_matched_all,by="Rec_ID") %>%
select(Rec_ID,date,year,month,pacfin_port_code,port_group_code,agency_code,drvid,FINAL_LENGTH,traps) %>%
distinct(Rec_ID,.keep_all = T) %>%
# count number of traps associated with each trip
mutate(ntraps=purrr::map_int(traps,nrow))
prop_vms_index <- readRDS(paste0(fp,"monthly_vms_representation_index.rds")) %>%
select(year,month,vessel_length_cat,prop_vms)
vessel_month_ntrap_weights <- traplocs %>%
ungroup() %>%
select(Rec_ID,date,agency_code,port_group_code,drvid,ntraps) %>%
mutate(year=year(date),month=month(date)) %>%
group_by(drvid,year,month) %>%
# count number of trips per vessel per month to use as weighting factor
mutate(ntrips_month=n_distinct(Rec_ID))
vessel_month_allweights <- traplocs %>%
# add the monthly weighting factor to the trap locations
mutate(vessel_length_cat=case_when(
FINAL_LENGTH > 0 & FINAL_LENGTH<30 ~ 1,
FINAL_LENGTH >= 30 & FINAL_LENGTH<40 ~ 2,
FINAL_LENGTH >= 40 & FINAL_LENGTH<50 ~ 3,
FINAL_LENGTH >=50~ 4
)) %>%
rowwise() %>%
mutate(month=which(month.name==month)) %>%
left_join(prop_vms_index) %>%
ungroup() %>%
left_join(vessel_month_ntrap_weights) %>%
# calculate overall weight
mutate(combined_weight=(1/prop_vms)*(1/ntrips_month)) %>%
select(Rec_ID,date,year,month,agency_code,port_group_code,drvid,ntraps,vessel_length_cat,prop_vms,ntrips_month,combined_weight)
saveRDS(vessel_month_ntrap_weights,file=paste0(fp,"vessel_month_trap_weights.rds"))
saveRDS(vessel_month_allweights,file=paste0(fp,"vessel_month_all_weights.rds"))
mean_traps_per_trip <- traplocs %>%
select(date,agency_code,port_group_code,drvid,ntraps) %>%
mutate(year=year(date),month=month(date)) %>%
group_by(year,month,drvid,agency_code,port_group_code) %>%
# mean number of traps per trip per vessel per month
summarise(traps_per_trip=mean(ntraps)) %>%
ungroup()
traps_per_trip_plot <- mean_traps_per_trip %>%
group_by(year,month) %>%
summarise(mean_traps_per_trip=mean(traps_per_trip)) %>%
mutate(day=1) %>%
unite(date,year,month,day,sep="-",remove = FALSE) %>%
mutate(date=as_date(date,format="%Y-%m-%d",tz="America/Los_Angeles")) %>%
ggplot(aes(date,mean_traps_per_trip))+
geom_line()+
scale_y_continuous(breaks=seq(0,500,by=100),labels=seq(0,500,by=100),limits=c(0,500))+
labs(x="Date",y="Mean Number of Traps per Dungeness Trip")
traps_per_trip_plot
total_traps_by_month_state <- mean_traps_per_trip %>%
group_by(year,month,agency_code) %>%
summarise(tot_traps=sum(traps_per_trip),nvessels=n_distinct(drvid)) %>%
ungroup() %>%
complete(year,month,agency_code,fill=list(tot_traps=0,nvessels=0)) %>%
mutate(day=15) %>%
unite(date,year,month,day,sep="-",remove = FALSE) %>%
mutate(date=as_date(date,format="%Y-%m-%d",tz="America/Los_Angeles"))
vessels_by_month_plot <- total_traps_by_month_state %>%
ggplot(aes(date,nvessels,fill=agency_code,col=agency_code))+
geom_bar(stat='identity',position='stack')+
scale_fill_nejm(name="State",labels=c("California","Oregon","Washington"))+
scale_color_nejm(name="State",labels=c("California","Oregon","Washington"))+
labs(x="Date",y="Number of Vessels",title="Total Number of VMS Vessels Recording Landings, by Month")+
scale_x_date(date_breaks= "6 months",date_labels="%b-%Y",expand=c(0,0))+
theme(axis.text.x.bottom = element_text(angle=90,vjust=+0.5,hjust=0),
panel.grid.minor = element_blank())
sim_traps_by_month_plot<- total_traps_by_month_state %>%
ggplot(aes(date,tot_traps/1000,color=agency_code,fill=agency_code))+
geom_bar(stat='identity',position='stack')+
scale_fill_nejm(name="State",labels=c("California","Oregon","Washington"))+
scale_color_nejm(name="State",labels=c("California","Oregon","Washington"))+
scale_x_date(date_breaks= "6 months",date_labels="%b-%Y",expand=c(0,0))+
labs(x="Date",y="Thousands of Traps",title="Total Number of Estimated Traps, by Month\nVMS Vessels Only")+
theme(axis.text.x.bottom = element_text(angle=90,vjust=+0.5,hjust=0),
panel.grid.minor = element_blank())
vessels_by_month_plot
sim_traps_by_month_plot
#save
fp_plots <- "C:/Users/Owen.Liu/Documents/NWFSC Research/Dungeness Fleet Dynamics/VMS DATA CONFIDENTIAL/Processed Data/owen processed/plots/"
ggsave(filename = paste0(fp_plots,"vessels_by_month.png"),vessels_by_month_plot,w=8,h=6)
ggsave(filename = paste0(fp_plots,"traps_by_month.png"),sim_traps_by_month_plot,w=8,h=6)
total_traps_by_month_port <- mean_traps_per_trip %>%
group_by(year,month,agency_code,port_group_code) %>%
summarise(tot_traps=sum(traps_per_trip),nvessels=n_distinct(drvid)) %>%
mutate(day=15) %>%
unite(date,year,month,day,sep="-",remove = FALSE) %>%
mutate(date=as_date(date,format="%Y-%m-%d",tz="America/Los_Angeles")) %>%
ungroup()
vessels_by_month_port_plot <-total_traps_by_month_port %>%
filter(agency_code=="C") %>%
ggplot(aes(date,nvessels,fill=port_group_code,col=port_group_code))+
geom_bar(stat='identity')+
scale_fill_nejm(name="Port Group")+
scale_color_nejm(name="Port Group")+
facet_wrap(~port_group_code)+
labs(x="Date",y="Number of Vessels",title="Total Number of VMS Vessels Recording Landings, by Month\nCalifornia Ports")+
scale_x_date(date_breaks= "1 year",date_labels="%b-%Y",expand=c(0,0))+
theme(axis.text.x.bottom = element_text(angle=90,vjust=+0.5,hjust=0),
panel.grid.minor = element_blank())
traps_by_month_port_plot <- total_traps_by_month_port %>%
filter(agency_code=="C") %>%
ggplot(aes(date,tot_traps/1000,fill=port_group_code,col=port_group_code))+
geom_bar(stat='identity')+
scale_fill_nejm(name="Port Group")+
scale_color_nejm(name="Port Group")+
facet_wrap(~port_group_code)+
labs(x="Date",y="Thousands of Traps",title="Total Number of Estimated Traps, by Month\nCalifornia Ports, VMS Vessels")+
scale_x_date(date_breaks= "1 year",date_labels="%b-%Y",expand=c(0,0))+
theme(axis.text.x.bottom = element_text(angle=90,vjust=+0.5,hjust=0),
panel.grid.minor = element_blank())
vessels_by_month_port_plot
traps_by_month_port_plot
ggsave(filename = paste0(fp_plots,"vessels_by_month_port.png"),vessels_by_month_port_plot,w=8,h=6)
ggsave(filename = paste0(fp_plots,"traps_by_month_port.png"),traps_by_month_port_plot,w=8,h=6)
knit_with_parameters('~/github/VMS-nwfsc/owen scripts/vertical_line_estimation.Rmd')
local({
# The directory where Pandoc will be extracted. Feel free
# to adjust this path as appropriate.
dir <- "~/rstudio-pandoc"
# The version of Pandoc to be installed.
version <- "2.7.1"
# Create and move to the requested directory.
dir.create(dir, showWarnings = FALSE, recursive = TRUE)
owd <- setwd(dir)
on.exit(setwd(owd), add = TRUE)
# Construct path to pandoc.
root <- "https://s3.amazonaws.com/rstudio-buildtools"
suffix <- sprintf("pandoc-%s-windows-x86_64.zip", version)
url <- file.path(root, "pandoc-rstudio", version, suffix)
# Download and extract pandoc.
file <- basename(url)
utils::download.file(url, destfile = file)
utils::unzip(file)
unlink(file)
# Write .Renviron to update the version of Pandoc used.
entry <- paste("RSTUDIO_PANDOC", shQuote(path.expand(dir)), sep = " = ")
contents <- if (file.exists("~/.Renviron")) readLines("~/.Renviron")
filtered <- grep("^RSTUDIO_PANDOC", contents, value = TRUE, invert = TRUE)
amended <- union(filtered, entry)
writeLines(amended, "~/.Renviron")
# Report change to the user.
writeLines("Updated .Renviron:\n")
writeLines(amended)
writeLines("\nPlease restart RStudio for these changes to take effect.")
})
